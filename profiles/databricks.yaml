# [Recommended] Uncomment fields below to set an MLflow experiment to track the pipeline execution.
# If unset, a default experiment based on runtime context will be created.
# experiment:
  # name: "/Shared/sklearn_regression_experiment"

# Set the registry server URI. This property is especially useful if you have a registry
# server thatâ€™s different from the tracking server.
# Profile could be created using https://github.com/databricks/databricks-cli#installation
# model_registry:
#   uri: "databricks://PROFILE_NAME"

# Use a section of the TLC Trip Record Dataset for model development
# (https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
INGEST_DATA_LOCATION: dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled
# Specify the format of the dataset
INGEST_DATA_FORMAT: spark_sql
# Use a section of the TLC Trip Record Dataset for model development
# (https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
INGEST_SCORING_DATA_LOCATION: dbfs:/databricks-datasets/nyctaxi-with-zipcodes/subsampled
# Specify the format of the dataset
INGEST_SCORING_DATA_FORMAT: spark_sql
# Override the default train / validation / test dataset split ratios
SPLIT_RATIOS: [0.75, 0.125, 0.125]
# Specify the output location of the batch scoring predict step
SCORED_OUTPUT_DATA_LOCATION: "taxi_regression_batch_scoring"
# Specify the output format of the batch scoring predict step
SCORED_OUTPUT_DATA_FORMAT: table